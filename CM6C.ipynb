{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CM6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris = pd.read_csv('iris_dataset_missing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris['sepal_width'].interpolate(method='linear', direction = 'forward', inplace=True) \n",
    "df_iris['petal_length'].interpolate(method='linear', direction = 'forward', inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_scaling(a):\n",
    "    xx=a\n",
    "    a_std = (xx- xx.min(axis = 0)) / (xx.max(axis = 0) - xx.min(axis = 0))\n",
    "    return a_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore(a):\n",
    "    xx=a\n",
    "    a_std = (xx- np.mean(xx)) / (np.std(xx))\n",
    "    return a_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_iris=df_iris.copy()\n",
    "mf_iris['sepal_length']=minmax_scaling(mf_iris['sepal_length'])\n",
    "mf_iris['sepal_width']=minmax_scaling(mf_iris['sepal_width'])\n",
    "mf_iris['petal_length']=minmax_scaling(mf_iris['petal_length'])\n",
    "mf_iris['petal_width']=minmax_scaling(mf_iris['petal_width'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "zf_iris=df_iris.copy()\n",
    "zf_iris['sepal_length']=zscore(zf_iris['sepal_length'])\n",
    "zf_iris['sepal_width']=zscore(zf_iris['sepal_width'])\n",
    "zf_iris['petal_length']=zscore(zf_iris['petal_length'])\n",
    "zf_iris['petal_width']=zscore(zf_iris['petal_width'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         7\n",
      "Iris-versicolor       0.88      1.00      0.93         7\n",
      " Iris-virginica       1.00      0.86      0.92         7\n",
      "\n",
      "       accuracy                           0.95        21\n",
      "      macro avg       0.96      0.95      0.95        21\n",
      "   weighted avg       0.96      0.95      0.95        21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(df_iris, test_size = 0.2, stratify = df_iris['species'], random_state = 98)\n",
    "X_train = train[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "y_train = train.species\n",
    "X_test = test[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "y_test = test.species\n",
    "k=10\n",
    "classifier = KNeighborsClassifier(n_neighbors = k)\n",
    "classifier = classifier.fit(X_train,y_train)\n",
    "scores = cross_val_score(classifier, X_train, y_train, cv=5)\n",
    "scoresMean = scores.mean()\n",
    "scoresStd = scores.std()\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Weighted KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         7\n",
      "Iris-versicolor       0.88      1.00      0.93         7\n",
      " Iris-virginica       1.00      0.86      0.92         7\n",
      "\n",
      "       accuracy                           0.95        21\n",
      "      macro avg       0.96      0.95      0.95        21\n",
      "   weighted avg       0.96      0.95      0.95        21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(df_iris, test_size = 0.2, stratify = df_iris['species'], random_state = 98)\n",
    "X_train = train[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "y_train = train.species\n",
    "X_test = test[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "y_test = test.species\n",
    "k=10\n",
    "classifier = KNeighborsClassifier(n_neighbors=k, metric='euclidean', weights='distance')\n",
    "classifier = classifier.fit(X_train,y_train)\n",
    "scores = cross_val_score(classifier, X_train, y_train, cv=5)\n",
    "scoresMean = scores.mean()\n",
    "scoresStd = scores.std()\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         7\n",
      "Iris-versicolor       0.86      0.86      0.86         7\n",
      " Iris-virginica       0.86      0.86      0.86         7\n",
      "\n",
      "       accuracy                           0.90        21\n",
      "      macro avg       0.90      0.90      0.90        21\n",
      "   weighted avg       0.90      0.90      0.90        21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(mf_iris, test_size = 0.2, stratify = mf_iris['species'], random_state = 98)\n",
    "X_train = train[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "y_train = train.species\n",
    "X_test = test[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "y_test = test.species\n",
    "k=7\n",
    "classifier = KNeighborsClassifier(n_neighbors = k)\n",
    "classifier = classifier.fit(X_train,y_train)\n",
    "scores = cross_val_score(classifier, X_train, y_train, cv=5)\n",
    "scoresMean = scores.mean()\n",
    "scoresStd = scores.std()\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weighted KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         7\n",
      "Iris-versicolor       0.88      1.00      0.93         7\n",
      " Iris-virginica       1.00      0.86      0.92         7\n",
      "\n",
      "       accuracy                           0.95        21\n",
      "      macro avg       0.96      0.95      0.95        21\n",
      "   weighted avg       0.96      0.95      0.95        21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(mf_iris, test_size = 0.2, stratify = mf_iris['species'], random_state = 98)\n",
    "X_train = train[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "y_train = train.species\n",
    "X_test = test[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "y_test = test.species\n",
    "k=7\n",
    "classifier = KNeighborsClassifier(n_neighbors = k, metric='euclidean', weights='distance')\n",
    "classifier = classifier.fit(X_train,y_train)\n",
    "scores = cross_val_score(classifier, X_train, y_train, cv=5)\n",
    "scoresMean = scores.mean()\n",
    "scoresStd = scores.std()\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weighted KNN for Iris database improved the results as it is clear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         7\n",
      "Iris-versicolor       0.86      0.86      0.86         7\n",
      " Iris-virginica       0.86      0.86      0.86         7\n",
      "\n",
      "       accuracy                           0.90        21\n",
      "      macro avg       0.90      0.90      0.90        21\n",
      "   weighted avg       0.90      0.90      0.90        21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "train, test = train_test_split(zf_iris, test_size = 0.2, stratify = zf_iris['species'], random_state = 98)\n",
    "X_train = train[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "y_train = train.species\n",
    "X_test = test[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "y_test = test.species\n",
    "k=7\n",
    "classifier = KNeighborsClassifier(n_neighbors = k)\n",
    "classifier = classifier.fit(X_train,y_train)\n",
    "scores = cross_val_score(classifier, X_train, y_train, cv=5)\n",
    "scoresMean = scores.mean()\n",
    "scoresStd = scores.std()\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Weighted KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         7\n",
      "Iris-versicolor       0.88      1.00      0.93         7\n",
      " Iris-virginica       1.00      0.86      0.92         7\n",
      "\n",
      "       accuracy                           0.95        21\n",
      "      macro avg       0.96      0.95      0.95        21\n",
      "   weighted avg       0.96      0.95      0.95        21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "train, test = train_test_split(zf_iris, test_size = 0.2, stratify = zf_iris['species'], random_state = 98)\n",
    "X_train = train[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "y_train = train.species\n",
    "X_test = test[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "y_test = test.species\n",
    "k=7\n",
    "classifier = KNeighborsClassifier(n_neighbors = k, metric='euclidean', weights='distance')\n",
    "classifier = classifier.fit(X_train,y_train)\n",
    "scores = cross_val_score(classifier, X_train, y_train, cv=5)\n",
    "scoresMean = scores.mean()\n",
    "scoresStd = scores.std()\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weighted KNN for Iris database improved the results as it is clear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('heart_disease_missing.csv')\n",
    "if(df.isnull().values.any()):\n",
    "    df = df.fillna(method = 'ffill')\n",
    "df = df[(np.abs(stats.zscore(df)) < 4).all(axis=1)]\n",
    "df = df[[ 'cp', 'thalach', 'exang', 'oldpeak', 'target']]\n",
    "df['oldpeak'].interpolate(method='linear', direction = 'forward', inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.70      0.72        20\n",
      "           1       0.75      0.78      0.77        23\n",
      "\n",
      "    accuracy                           0.74        43\n",
      "   macro avg       0.74      0.74      0.74        43\n",
      "weighted avg       0.74      0.74      0.74        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:,:-1].values\n",
    "y = df.iloc[:,4].values\n",
    "X_t, X_test, y_t, y_test =  train_test_split(X,y,test_size = 0.2, random_state= 98)\n",
    "X_train, X_val, y_train, y_val =  train_test_split(X_t,y_t,test_size = 0.1, random_state= 98)\n",
    "k = 11\n",
    "classifier = KNeighborsClassifier(n_neighbors = k)\n",
    "classifier = classifier.fit(X_train,y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.70      0.72        20\n",
      "           1       0.75      0.78      0.77        23\n",
      "\n",
      "    accuracy                           0.74        43\n",
      "   macro avg       0.74      0.74      0.74        43\n",
      "weighted avg       0.74      0.74      0.74        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:,:-1].values\n",
    "y = df.iloc[:,4].values\n",
    "X_t, X_test, y_t, y_test =  train_test_split(X,y,test_size = 0.2, random_state= 98)\n",
    "X_train, X_val, y_train, y_val =  train_test_split(X_t,y_t,test_size = 0.1, random_state= 98)\n",
    "k = 11\n",
    "classifier = KNeighborsClassifier(n_neighbors = k,algorithm='brute')\n",
    "classifier = classifier.fit(X_train,y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.70      0.72        20\n",
      "           1       0.75      0.78      0.77        23\n",
      "\n",
      "    accuracy                           0.74        43\n",
      "   macro avg       0.74      0.74      0.74        43\n",
      "weighted avg       0.74      0.74      0.74        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:,:-1].values\n",
    "y = df.iloc[:,4].values\n",
    "X_t, X_test, y_t, y_test =  train_test_split(X,y,test_size = 0.2, random_state= 98)\n",
    "X_train, X_val, y_train, y_val =  train_test_split(X_t,y_t,test_size = 0.1, random_state= 98)\n",
    "k = 11\n",
    "classifier = KNeighborsClassifier(n_neighbors = k,algorithm='kd_tree')\n",
    "classifier = classifier.fit(X_train,y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.70      0.72        20\n",
      "           1       0.75      0.78      0.77        23\n",
      "\n",
      "    accuracy                           0.74        43\n",
      "   macro avg       0.74      0.74      0.74        43\n",
      "weighted avg       0.74      0.74      0.74        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:,:-1].values\n",
    "y = df.iloc[:,4].values\n",
    "X_t, X_test, y_t, y_test =  train_test_split(X,y,test_size = 0.2, random_state= 98)\n",
    "X_train, X_val, y_train, y_val =  train_test_split(X_t,y_t,test_size = 0.1, random_state= 98)\n",
    "k = 11\n",
    "classifier = KNeighborsClassifier(n_neighbors = k,algorithm='ball_tree')\n",
    "classifier = classifier.fit(X_train,y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the change of algorithm cannot be a good solution becuase the results are the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### weighted KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.60      0.62        20\n",
      "           1       0.67      0.70      0.68        23\n",
      "\n",
      "    accuracy                           0.65        43\n",
      "   macro avg       0.65      0.65      0.65        43\n",
      "weighted avg       0.65      0.65      0.65        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:,:-1].values\n",
    "y = df.iloc[:,4].values\n",
    "X_t, X_test, y_t, y_test =  train_test_split(X,y,test_size = 0.2, random_state= 98)\n",
    "X_train, X_val, y_train, y_val =  train_test_split(X_t,y_t,test_size = 0.1, random_state= 98)\n",
    "k = 11\n",
    "classifier = KNeighborsClassifier(n_neighbors = k, metric='euclidean', weights='distance')\n",
    "classifier = classifier.fit(X_train,y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.65      0.70        20\n",
      "           1       0.73      0.83      0.78        23\n",
      "\n",
      "    accuracy                           0.74        43\n",
      "   macro avg       0.75      0.74      0.74        43\n",
      "weighted avg       0.75      0.74      0.74        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X = df.iloc[:,:-1].values\n",
    "y = df.iloc[:,4].values\n",
    "X_t, X_test, y_t, y_test =  train_test_split(X,y,test_size = 0.2, random_state= 98)\n",
    "X_train, X_val, y_train, y_val =  train_test_split(X_t,y_t,test_size = 0.1, random_state= 98)\n",
    "X_train = zscore(X_train)\n",
    "X_test = zscore(X_test)\n",
    "X_val = zscore(X_val)\n",
    "k = 9\n",
    "classifier = KNeighborsClassifier(n_neighbors = k)\n",
    "classifier = classifier.fit(X_train,y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### weighted KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.65      0.70        20\n",
      "           1       0.73      0.83      0.78        23\n",
      "\n",
      "    accuracy                           0.74        43\n",
      "   macro avg       0.75      0.74      0.74        43\n",
      "weighted avg       0.75      0.74      0.74        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X = df.iloc[:,:-1].values\n",
    "y = df.iloc[:,4].values\n",
    "X_t, X_test, y_t, y_test =  train_test_split(X,y,test_size = 0.2, random_state= 98)\n",
    "X_train, X_val, y_train, y_val =  train_test_split(X_t,y_t,test_size = 0.1, random_state= 98)\n",
    "X_train = zscore(X_train)\n",
    "X_test = zscore(X_test)\n",
    "X_val = zscore(X_val)\n",
    "k = 9\n",
    "classifier = KNeighborsClassifier(n_neighbors = k, metric='euclidean', weights='distance')\n",
    "classifier = classifier.fit(X_train,y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.70      0.76        20\n",
      "           1       0.77      0.87      0.82        23\n",
      "\n",
      "    accuracy                           0.79        43\n",
      "   macro avg       0.80      0.78      0.79        43\n",
      "weighted avg       0.79      0.79      0.79        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X = df.iloc[:,:-1].values\n",
    "y = df.iloc[:,4].values\n",
    "X_t, X_test, y_t, y_test =  train_test_split(X,y,test_size = 0.2, random_state= 98)\n",
    "X_train, X_val, y_train, y_val =  train_test_split(X_t,y_t,test_size = 0.1, random_state= 98)\n",
    "X_train = minmax_scaling(X_train)\n",
    "X_test = minmax_scaling(X_test)\n",
    "X_val = minmax_scaling(X_val)\n",
    "k = 20\n",
    "classifier = KNeighborsClassifier(n_neighbors = k)\n",
    "classifier = classifier.fit(X_train,y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weighted KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.70      0.78        20\n",
      "           1       0.78      0.91      0.84        23\n",
      "\n",
      "    accuracy                           0.81        43\n",
      "   macro avg       0.83      0.81      0.81        43\n",
      "weighted avg       0.82      0.81      0.81        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X = df.iloc[:,:-1].values\n",
    "y = df.iloc[:,4].values\n",
    "X_t, X_test, y_t, y_test =  train_test_split(X,y,test_size = 0.2, random_state= 98)\n",
    "X_train, X_val, y_train, y_val =  train_test_split(X_t,y_t,test_size = 0.1, random_state= 98)\n",
    "X_train = minmax_scaling(X_train)\n",
    "X_test = minmax_scaling(X_test)\n",
    "X_val = minmax_scaling(X_val)\n",
    "k = 20\n",
    "classifier = KNeighborsClassifier(n_neighbors = k, metric='euclidean', weights='distance')\n",
    "classifier = classifier.fit(X_train,y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results, for Iris data base accuracy of 94 % is reached with and without normalization. But with normalization number of neighborhoods is lower than without normalization. But for heart disease data base for 4 features, without normalization, the accuracy is better. However, other parameters by normalization have better situation like marco avg and weighted avg. \n",
    "Weighted KNN for Iris database improved the results as it is clear. \n",
    "By changing the K in knn, we can reach better accuracy if the model is not overfitted. In some cases, increse of K can decrease the accurasy of model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refrences\n",
    "https://www.kdnuggets.com/2019/07/classifying-heart-disease-using-k-nearest-neighbors.html/2\n",
    "https://towardsdatascience.com/exploring-classifiers-with-python-scikit-learn-iris-dataset-2bcb490d2e1b\n",
    "https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation\n",
    "https://www.kdnuggets.com/2019/07/classifying-heart-disease-using-k-nearest-neighbors.html/2\n",
    "https://www.w3resource.com/python-exercises/pandas/missing-values/python-pandas-missing-values-exercise-15.php"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
